name: TV Scraper

on:
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes
  workflow_dispatch:        # Manual trigger

jobs:
  scrape-tv:
    runs-on: ubuntu-latest
    env:
      ENGINE_URL: https://ugboard-engine.onrender.com
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install aiohttp requests
    
    - name: Run TV Scraper
      env:
        INGEST_TOKEN: ${{ secrets.INGEST_TOKEN }}
      run: |
        python -c "
import asyncio
import aiohttp
import os
import json
from datetime import datetime

async def test_scraper():
    engine_url = '${{ env.ENGINE_URL }}'
    token = os.getenv('INGEST_TOKEN')
    
    if not token:
        print('❌ INGEST_TOKEN not set')
        return
    
    headers = {
        'Authorization': f'Bearer {token}',
        'Content-Type': 'application/json'
    }
    
    # Test data
    payload = {
        'items': [{
            'title': 'GitHub Actions Test',
            'artist': 'System Test',
            'plays': 1,
            'score': 50.0,
            'station': 'GitHub Actions'
        }],
        'source': 'github_actions_test',
        'timestamp': datetime.utcnow().isoformat()
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        async with session.post(f'{engine_url}/ingest/tv', json=payload) as resp:
            if resp.status == 200:
                result = await resp.json()
                print(f'✅ Test successful: {result[\"message\"]}')
            else:
                error = await resp.text()
                print(f'❌ Test failed: {error}')

asyncio.run(test_scraper())
        "
